# Laboratorio 1 - Dise√±o Arquitect√≥nico

**Nombre:** Sebastian Rios Sabogal

**C√©dula:** 1143825130

**Repositorio del sistema analizado:** [https://github.com/apache/airflow](https://github.com/apache/airflow)

---

## 1. Introducci√≥n

[Apache Airflow](https://airflow.apache.org/) es una plataforma open source para la orquestaci√≥n de flujos de trabajo programables ([DAGs](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/overview.html)), ampliamente utilizada en ingenier√≠a de datos, ciencia de datos y automatizaci√≥n de procesos. Fue originalmente desarrollada por Airbnb y actualmente es un proyecto de la Apache Software Foundation.

Airflow permite definir flujos complejos como c√≥digo Python y ejecutarlos de forma din√°mica y distribuida. Gracias a su arquitectura modular y escalable, es ideal para flujos de trabajo intensivos en datos y tareas concurrentes.

---

## 2. Justificaci√≥n de selecci√≥n

Apache Airflow es un sistema altamente representativo para el an√°lisis arquitect√≥nico de **software a gran escala**, por las siguientes razones, que evidencian atributos clave como **modularidad**, **concurrencia**, **escalabilidad** y **adaptabilidad**:

- **Cantidad de componentes**: Airflow est√° compuesto por varios **servicios distribuidos** que se comunican entre s√≠, cada uno con **responsabilidades bien delimitadas**:
    
    - **Webserver**: expone una interfaz gr√°fica y una API REST para la gesti√≥n y monitoreo de flujos de trabajo.
    - **Scheduler**: analiza los DAGs y determina qu√© tareas deben ejecutarse y cu√°ndo.
    - **Broker**: gestiona la cola de tareas entre Scheduler y Workers, usando RabbitMQ o Redis.
    - **Workers**: ejecutan las tareas planificadas, de forma concurrente y distribuida.
    - **Metadatabase**: almac√©n persistente que registra el estado de ejecuci√≥n, logs, DAGs y metainformaci√≥n.

    |üí°Ejemplo de caso de uso: En un entorno productivo en GCP (Google Cloud Platform), se despliegan estos componentes en contenedores separados (por ejemplo en Kubernetes), lo cual permite escalar el n√∫mero de Workers independientemente del Webserver o Scheduler

- **Alto grado de concurrencia**: Airflow est√° dise√±ado para ejecutar m√∫ltiples tareas en **paralelo**, permite ejecuci√≥n simult√°nea de tareas en **cl√∫steres**, usando estrategias como:

    - **CeleryExecutor**: distribuci√≥n de tareas usando colas de mensajes (AMQP/Redis).
    - **KubernetesExecutor**: cada tarea se ejecuta como un microservicio aislado en un pod de Kubernetes.

    |üí°Ejemplo de caso de uso: En una pipeline de ciencia de datos con 50 tareas independientes que procesan distintos segmentos de un dataset, Airflow puede lanzar 50 pods simult√°neos (usando KubernetesExecutor), lo cual acelera el tiempo total de procesamiento.

- **Manejo de grandes vol√∫menes de datos**: Airflow es frecuentemente usado para orquestar flujos de **procesamiento de datos** (ETL/ELT) y flujos de machine learning, integrando herramientas como:

    - Spark
    - Hadoop
    - BigQuery
    - Amazon S3
    - Snowflake
    - Redshift

    |üí°Ejemplo de caso de uso: Una empresa de retail puede usar Airflow para coordinar el procesamiento nocturno de 1 TB de transacciones diarias en un cl√∫ster Spark, incluyendo carga, transformaci√≥n y escritura a un data warehouse (como Redshift).

- **Uso en sistemas complejos**: Airflow no solo se usa en entornos de procesamiento de datos, sino tambi√©n como orquestador general de **procesos distribuidos y ciberf√≠sicos**, donde se requiere integrar componentes heterog√©neos.

    |üí°Ejemplo de caso de uso: En el contexto Ciberf√≠sico de una f√°brica inteligente (Industria 4.0), Airflow se utiliza para coordinar flujos que recolectan telemetr√≠a de sensores de maquinaria, detectan anomal√≠as con ML, y disparan alertas de mantenimiento.

---

## 3. An√°lisis Arquitect√≥nico

### 3.1 Estilo arquitect√≥nico predominante

Apache Airflow adopta una **arquitectura h√≠brida** que integra **m√∫ltiples estilos arquitect√≥nicos cl√°sicos y modernos**, lo que le permite atender requisitos clave como **escalabilidad**, **flexibilidad**, **resiliencia** y **mantenibilidad**:

- **Microservicios coordinados con mensajer√≠a as√≠ncrona**

    Airflow puede configurarse con ejecutores como CeleryExecutor o KubernetesExecutor, en los cuales:

    - Las **tareas se distribuyen as√≠ncronamente** desde el **Scheduler** a los **Workers** a trav√©s de un **Broker** de mensajes (Redis o RabbitMQ).

    - Cada **Worker** o **Pod** (en Kubernetes) act√∫a como una **unidad funcional independiente**, lo que refleja un **patr√≥n de microservicio** con **bajo acoplamiento** y **alta cohesi√≥n**.

    |üí°Ejemplo: Cada tarea del DAG puede ejecutarse como un contenedor aut√≥nomo, con su propio entorno, recursos y l√≥gica de negocio, lo que permite ejecutar tareas heterog√©neas simult√°neamente sin interferencias.

- **Client-Server (Frontend / Backend)**

    Airflow ofrece una **interfaz gr√°fica** (Webserver) que act√∫a como **cliente web**, la cual se comunica con **componentes backend** mediante:

    - Llamadas **HTTP/REST** hacia la **API REST** (backend de control y monitoreo).
    - Conexiones **SQL** hacia la **base de datos de metadatos**.

    |üí°Ejemplo: Un usuario accede a la UI web para visualizar el DAG, consulta el historial de ejecuci√≥n y lanza una tarea manual; esta operaci√≥n fluye desde el **navegador** ‚Üí **Webserver** ‚Üí **API** ‚Üí **Scheduler** ‚Üí **Broker**.

- **Pipeline / Pipe-and-Filter**

    Los flujos de trabajo en Airflow se modelan como **DAGs** (Directed Acyclic Graphs), en los que:

    - Cada **nodo es una tarea** (filter).
    - Las **aristas representan dependencias** entre tareas.
    - El flujo de datos o ejecuci√≥n se canaliza de una tarea a otra, siguiendo un modelo tipo **pipe-and-filter**.

    |üí°Ejemplo: Un pipeline que **extrae datos** ‚Üí **los transforma** ‚Üí **los carga** en un data warehouse, puede representarse como **ExtractTask** ‚Üí **TransformTask** ‚Üí **LoadTask**, donde cada tarea es ejecutada de forma **independiente** y **secuencial**.


- **Repositorio compartido**

    Todos los componentes de Airflow acceden a una base de datos relacional compartida (Metadatabase), este patr√≥n sigue el estilo de Repositorio Compartido (Shared Database Repository), donde el estado del sistema se centraliza para garantizar coherencia eventual:

    - **Almacena definiciones** de DAGs, historial de ejecuciones, logs, variables de entorno, conexiones, etc.
    - **Sirve como mecanismo de coordinaci√≥n** entre componentes (Scheduler, Workers, Webserver, CLI).

    |üí°Ejemplo: El **Scheduler** consulta la base de datos para determinar qu√© tareas est√°n listas, mientras que los **Workers** reportan el resultado de ejecuci√≥n escribiendo en esa misma base de datos.

Esta arquitectura h√≠brida permite a Apache Airflow cumplir con los requisitos de los sistemas de software a gran escala, como:

- Escalabilidad horizontal de ejecuci√≥n.
- Resiliencia ante fallos parciales de componentes.
- Adaptabilidad al entorno (cloud, on-premise, edge).
- Observabilidad distribuida y trazabilidad total del flujo de datos.

La combinaci√≥n de estos estilos aporta las siguientes ventajas:

| Estilo                      | Aporta...                                              |
|-----------------------------|--------------------------------------------------------|
| Microservicios              | Desacoplamiento, escalabilidad, aislamiento de fallos |
| Client-Server               | Separaci√≥n de UI y l√≥gica de control                  |
| Pipe-and-Filter (DAGs)      | Flujo modular, composici√≥n flexible de procesos       |
| Repositorio compartido      | Coordinaci√≥n, auditabilidad, persistencia compartida  |

---

### 3.2 Componentes y conectores

A continuaci√≥n se describen los principales componentes arquitect√≥nicos involucrados en la ejecuci√≥n de flujos de trabajo en Apache Airflow, considerando tanto los servicios funcionales internos como los **elementos de infraestructura** que soportan su operaci√≥n a gran escala:

| Componente                       | Rol principal                                                                 | Conectores clave                               |
|----------------------------------|-------------------------------------------------------------------------------|------------------------------------------------|
| **Web Browser**                 | Interfaz cliente utilizada por usuarios finales para acceder a la UI web.   | HTTP/REST hacia Load Balancer                  |
| **Load Balancer**              | Distribuye el tr√°fico entrante entre instancias del Webserver.              | HTTP/REST hacia API Gateway                    |
| **API Gateway**                | Entrada unificada a los servicios REST de Airflow.                          | HTTP/REST hacia Webserver                      |
| **Webserver**                  | Renderiza la UI web, sirve la API REST y se comunica con componentes backend. | HTTP/REST hacia API REST; SQL hacia Metadatabase |
| **API REST**                   | Provee endpoints RESTful para automatizaci√≥n y control externo.             | HTTP/REST desde Webserver                      |
| **Scheduler**                  | Eval√∫a DAGs, planifica tareas y las publica al Broker.                      | SQL a Metadatabase; AMQP/Redis al Broker       |
| **Broker (RabbitMQ / Redis)** | Cola de tareas para distribuci√≥n as√≠ncrona entre Scheduler y Workers.       | AMQP/Redis bidireccional                       |
| **Worker Pool**                | Infraestructura base para ejecutar tareas (pueden ser pods, procesos, etc.).| Recibe tareas desde el Broker                  |
| **Microservice - Task Executor** | Instancia aislada que ejecuta una tarea espec√≠fica como microservicio.      | SQL hacia Metadatabase                         |
| **Metadatabase**               | Repositorio central con informaci√≥n de DAGs, tareas, variables, logs, etc.  | SQL desde Webserver, Scheduler, Workers, Microservices |
| **Database / Storage**        | Persistencia f√≠sica de datos (PostgreSQL, MySQL, u otro backend).           | Usada por Metadatabase                         |
| **CLI / Scripts**             | Herramientas de l√≠nea de comandos o automatizaci√≥n externa.                 | CLI/API hacia Webserver; CLI hacia Scheduler   |

---

#### Conectores utilizados

- **HTTP/REST**: Para interacci√≥n con el usuario (UI), API Gateway y Webserver.
- **AMQP / Redis**: Protocolo de mensajer√≠a para distribuci√≥n de tareas entre Scheduler y Workers.
- **SQL**: Acceso persistente a la Metadatabase desde todos los componentes clave.
- **CLI / API**: Interfaces administrativas para ejecuci√≥n de comandos, automatizaci√≥n y orquestaci√≥n externa.

---

## 4. Modelo Component & Connector (C&C)

### 4.1 Diagrama visual estilo Mermaid

```mermaid
graph TD
    subgraph Cliente
        A[Usuario / Admin]
        WB[Web Browser]
        A --> WB
    end

    subgraph Infraestructura
        LB[Load Balancer]
        GW[API Gateway]
        DB[Database / Storage]
    end

    subgraph Airflow Cluster
        B[Webserver]
        G[API REST]
        C[Scheduler]
        D[Broker - RabbitMQ / Redis]
        F[Workers]
        M[Microservice - Task Executor]
        E[Metadatabase]
        H[CLI / Scripts]
    end

    WB -->|HTTP/REST| LB
    LB --> GW
    GW -->|HTTP/REST| B
    B -->|HTTP/REST| G
    B -->|SQL| E
    C -->|SQL| E
    C -->|AMQP / Redis| D
    D -->|AMQP / Redis| F
    F --> M
    M -->|SQL| E
    H -->|CLI / API| B
    H -->|CLI| C

    E --> DB
```

[![](https://mermaid.ink/img/pako:eNp1U9tu4jAQ_RXLz0BJwy15WCkXbhKRKLCKtEkfTDJAVIiRYy9tgX_fSQIllK2f4nPOXM54cqQRj4GadC3YfkMWbpgSPJlaloCzTSCVUKL5sYLfmWIi4eSJWPEuSV9vnG8HPiyJLfghA1EhLFKv_0K6RCCNw_RbnXG6EgwyKVQklWC30IkdTDiLic22LI3usg79wJqOyZBJOLCPCuHagcskW7IMsMu55IKt4fXn4lYiVlt-QLMqkyBuiQo_aOXvfd2i7Kw_X1RAJ5hHG4jV9k7qBjiMNxCkTmZsuUyk94IdzSBOsopqEPhcoKqKeYGXRILnxZMIMH7BsjfSf4dIoZ-KsB94IFl88VshRoEzGef-I5HsZfbo37fzZzmNFovpU-7mhMMumUnB4IDL69D_LrzoHhIMq_j8ZXIi_RJxfkAs72V6nciJXLbP_Q81KKlB0ZhXXryHpKMCKX3jI301-oWfiHO13y9SuTat4fInMTVx-aBGdyB2LL_SY64LqdzADkJq4mcMK6a2MqRhesawPUv_cL67Rgqu1pvrRe3xScBNGK7YTYHTB-FwlUpqPmtFBmoe6Ts1W3qjqXc6WkvrtfV2TzNq9IOaHb3RMppdQ-9p3Wej2-qda_SzKNlsGK2m0dHaOsJtXW_2ahQnhbvhlT908V-f_wGdpRvs?type=png)](https://mermaid.live/edit#pako:eNp1U9tu4jAQ_RXLz0BJwy15WCkXbhKRKLCKtEkfTDJAVIiRYy9tgX_fSQIllK2f4nPOXM54cqQRj4GadC3YfkMWbpgSPJlaloCzTSCVUKL5sYLfmWIi4eSJWPEuSV9vnG8HPiyJLfghA1EhLFKv_0K6RCCNw_RbnXG6EgwyKVQklWC30IkdTDiLic22LI3usg79wJqOyZBJOLCPCuHagcskW7IMsMu55IKt4fXn4lYiVlt-QLMqkyBuiQo_aOXvfd2i7Kw_X1RAJ5hHG4jV9k7qBjiMNxCkTmZsuUyk94IdzSBOsopqEPhcoKqKeYGXRILnxZMIMH7BsjfSf4dIoZ-KsB94IFl88VshRoEzGef-I5HsZfbo37fzZzmNFovpU-7mhMMumUnB4IDL69D_LrzoHhIMq_j8ZXIi_RJxfkAs72V6nciJXLbP_Q81KKlB0ZhXXryHpKMCKX3jI301-oWfiHO13y9SuTat4fInMTVx-aBGdyB2LL_SY64LqdzADkJq4mcMK6a2MqRhesawPUv_cL67Rgqu1pvrRe3xScBNGK7YTYHTB-FwlUpqPmtFBmoe6Ts1W3qjqXc6WkvrtfV2TzNq9IOaHb3RMppdQ-9p3Wej2-qda_SzKNlsGK2m0dHaOsJtXW_2ahQnhbvhlT908V-f_wGdpRvs)

- **Usuario / Admin**

    - Representa al usuario final que interact√∫a con el sistema.
    - Puede ser un analista, operador o ingeniero de datos que accede a la interfaz web de Airflow para visualizar, administrar y lanzar flujos de trabajo.

- **Web Browser**

    - Cliente HTTP que se comunica con la interfaz de usuario de Airflow.
    - Act√∫a como front-end de acceso a la UI, generalmente accediendo v√≠a HTTPS al balanceador de carga.

- **Load Balancer**

    - Componente que distribuye las peticiones entrantes entre m√∫ltiples instancias del Webserver.
    - Proporciona **alta disponibilidad y escalabilidad horizontal** en entornos de producci√≥n.
    - Puede estar implementado como un servicio de Kubernetes (Ingress), un balanceador de nube (AWS ALB, GCP LB), o una soluci√≥n como NGINX/HAProxy.

- **API Gateway**

    - Act√∫a como **frontera de entrada al backend**, validando y enroutando llamadas REST hacia los servicios internos.
    - Puede encargarse de seguridad (autenticaci√≥n/autorizaci√≥n), rate limiting, logging y control de versiones de API.
    - Es com√∫n usar Kong, Traefik, Ambassador o el API Gateway de una nube p√∫blica.

- **Database / Storage**

    - Almacenamiento f√≠sico utilizado por la base de datos de metadatos (Metadatabase).
    - Suele ser una base de datos relacional como PostgreSQL o MySQL, y puede estar respaldada por vol√∫menes persistentes o servicios administrados.

- **Webserver**

    - Servicio que renderiza la interfaz de usuario web y expone la API REST p√∫blica de Airflow.
    - Permite a los usuarios visualizar DAGs, monitorear ejecuciones, acceder a logs, lanzar tareas, etc.

- **API REST**

    - Conjunto de endpoints RESTful expuestos por el Webserver.
    - Permite interactuar program√°ticamente con Airflow (por ejemplo, crear DAGs, ejecutar tareas, obtener logs).
    - Sigue el est√°ndar OpenAPI y permite integraci√≥n con scripts, CI/CD y plataformas externas.

- **Scheduler**

    - N√∫cleo de control del sistema: analiza los DAGs registrados y determina cu√°ndo deben ejecutarse las tareas.
    - Inserta las tareas listas en el Broker de mensajer√≠a.
    - Tiene una visi√≥n global del estado de ejecuci√≥n del sistema.

- **Broker (Redis / RabbitMQ)**  

    - Sistema de mensajer√≠a as√≠ncrono utilizado para distribuir las tareas programadas a los Workers.
    - RabbitMQ usa AMQP, Redis es m√°s simple pero eficiente para colas en memoria.
    - Permite desacoplar la planificaci√≥n y la ejecuci√≥n.

- **Workers**  

    - Proceso (o pod) encargado de ejecutar las tareas asignadas.
    - Puede haber m√∫ltiples Workers, escalables horizontalmente.
    - Toman tareas del Broker y reportan resultados en la Metadatabase.
    - En el caso de KubernetesExecutor, pueden ser pods transitorios que ejecutan tareas aisladas.

- **Microservice ‚Äì Task Executor**

    - Representa una instancia concreta e independiente de ejecuci√≥n de una tarea del DAG.
    - En KubernetesExecutor, cada tarea es ejecutada como un microservicio autosuficiente (un pod) con su propio entorno, l√≥gica, y recursos.
    - Refleja una arquitectura serverless y altamente desacoplada.

- **Metadatabase (PostgreSQL / MySQL)**  

    - Base de datos central que mantiene el estado global del sistema.
    - Definiciones de DAGs
    - Historial de ejecuciones
    - Logs y auditor√≠a
    - Variables, conexiones y configuraciones
    - Es accedida por casi todos los componentes: Webserver, Scheduler, Workers y Microservicios.

- **CLI / Scripts**

    - Herramientas de l√≠nea de comandos para interacci√≥n directa con Airflow (airflow CLI).
    - Permiten iniciar DAGs, visualizar estados, pausar tareas, cargar configuraciones, entre otras operaciones.
    - Se comunican con el Webserver y Scheduler seg√∫n la operaci√≥n.

---

## 5. Conclusiones

Apache Airflow representa un caso realista, maduro y robusto para el estudio de **arquitecturas distribuidas modernas**, especialmente aquellas orientadas al procesamiento intensivo de datos, orquestaci√≥n de tareas y automatizaci√≥n de procesos complejos. A trav√©s de una clara separaci√≥n de responsabilidades, uso de mensajer√≠a as√≠ncrona y patrones de orquestaci√≥n, logra un sistema resiliente, escalable y extensible.

Su arquitectura no solo cumple con los principios de software a gran escala, sino que tambi√©n es adaptable a entornos h√≠bridos (cloud, edge, ciberf√≠sicos), y altamente integrable con el ecosistema de datos actual.

Airflow encarna m√∫ltiples principios clave de la arquitectura de software a gran escala:

- **Separaci√≥n de responsabilidades**: cada componente (Scheduler, Worker, Webserver, etc.) cumple una funci√≥n espec√≠fica, lo que facilita el mantenimiento, la escalabilidad individual y la evoluci√≥n del sistema.
- **Desacoplamiento mediante mensajer√≠a as√≠ncrona**: el uso de un Broker como intermediario entre productores (Scheduler) y consumidores (Workers) desacopla tiempo y espacio, permitiendo escalamiento horizontal y tolerancia a fallos.
- **Modelo de ejecuci√≥n basado en DAGs**: el enfoque declarativo permite visualizar claramente las dependencias entre tareas, facilitando su depuraci√≥n, reuso y composici√≥n.
- **Persistencia y trazabilidad centralizada**: la Metadatabase act√∫a como un punto √∫nico de verdad para el estado del sistema, lo que permite an√°lisis, auditor√≠a, debugging e integraci√≥n con herramientas externas.

Airflow no solo cumple con los principios de dise√±o de sistemas distribuidos escalables, sino que tambi√©n se adapta a entornos de despliegue cada vez m√°s diversos y complejos:

- **Cloud-native**: puede desplegarse f√°cilmente en plataformas como Kubernetes, y adaptarse a arquitecturas serverless mediante ejecutores como KubernetesExecutor.
- **Edge + Cloud h√≠brido**: se integra con fuentes de datos ubicuas (IoT, APIs externas) y puede coordinar el procesamiento entre dispositivos perif√©ricos y la nube.
- **Sistemas ciberf√≠sicos**: permite orquestar procesos donde interact√∫an elementos f√≠sicos (sensores, actuadores) y software anal√≠tico (modelos ML, ETL, alertas), con visibilidad y control desde la UI.

Adem√°s, su modelo de **extensibilidad basada en plugins**, su **API REST** abierta, y su ecosistema en expansi√≥n lo convierten en una plataforma altamente integrable con tecnolog√≠as como:

- Apache Spark, Hadoop, Kafka.
- Bases de datos SQL y NoSQL.
- Servicios de nube como S3, BigQuery, Redshift.
- Herramientas de CI/CD y DataOps.

Por estas razones, Apache Airflow constituye una **referencia pedag√≥gica y pr√°ctica** para el an√°lisis, modelado y dise√±o de sistemas de software a gran escala, cumpliendo con atributos cr√≠ticos como:

- **Escalabilidad**
    
    Capacidad del sistema para aumentar su rendimiento o capacidad al a√±adir m√°s recursos (horizontal o verticalmente), sin necesidad de redise√±o significativo.

- **Resiliencia**

    Habilidad del sistema para recuperarse autom√°ticamente de fallos parciales y continuar operando sin interrupciones totales.

- **Mantenibilidad**

    Facilidad con la que se pueden modificar, actualizar, corregir o extender los componentes del sistema de forma segura y controlada.

- **Adaptabilidad**

    Capacidad del sistema para ajustarse a nuevos entornos, requisitos o tecnolog√≠as sin redise√±os dr√°sticos (por ejemplo, migrar de on-premise a cloud).

- **Observabilidad**

    Grado en que el sistema expone su comportamiento interno mediante m√©tricas, logs y trazas, facilitando el monitoreo y diagn√≥stico proactivo.

Apache Airflow es una plataforma ideal para aplicar t√©cnicas de evaluaci√≥n arquitect√≥nica, an√°lisis de calidad, y exploraci√≥n de patrones de integraci√≥n en arquitecturas distribuidas modernas.
