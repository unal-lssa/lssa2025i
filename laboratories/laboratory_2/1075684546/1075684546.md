# [LSSA_2025i] - U2 - Laboratory 2

## Full name: José Fabián García Camargo

## 1. Delivery

- Add new component type (**Load balancer** and **Monitoring**).

## 2. Description

The solution proposed for the laboratory was the creation of a LoadBalancer that is responsible for correctly redistributing the requests to the Backend services, in addition to the management of metrics through "Prometheus", for real-time monitoring of:

- Rate of requests per backend
- Response time
- Service status
- Resource usage

## 3. Project Structure

### 3.1. DSL Definition (`arch.tx`)

The Domain-Specific Language (DSL) defines the grammar for describing the system architecture:

```
Model:
    'architecture' ':'
        elements*=Element
;

Element:
    Component | Connector
;

Component:
    'component' type=ComponentType name=ID
;

Connector:
    'connector' type=ConnectorType from=[Component] '->' to=[Component]
;

ComponentType:
    'database' | 'backend' | 'frontend' | 'load_balancer' | 'monitoring'
;

ConnectorType:
    'http' | 'db_connector' | 'metrics'
;
```

### 3.2. Metamodel Creation (`metamodel.py`)

The metamodel is created from the DSL grammar:

```python
import os 
from textx import metamodel_from_file

def create_metamodel():
    grammar = os.path.join(os.path.dirname(__file__), 'arch.tx')
    return metamodel_from_file(grammar)
```

### 3.3. Model Definition (`model.arch`)

The actual model describing the system architecture:

```
architecture:
    component frontend lssa_fe
    component load_balancer lssa_lb
    component backend lssa_be1
    component backend lssa_be2
    component monitoring lssa_monitor
    component database lssa_db

    connector http lssa_fe -> lssa_lb
    connector http lssa_lb -> lssa_be1
    connector http lssa_lb -> lssa_be2
    connector metrics lssa_monitor -> lssa_lb
    connector metrics lssa_monitor -> lssa_be1
    connector metrics lssa_monitor -> lssa_be2
    connector db_connector lssa_be1 -> lssa_db
    connector db_connector lssa_be2 -> lssa_db
```

### 3.4. Generation Script (`generation.py`)

The main script that orchestrates the generation process:

```python
from metamodel import create_metamodel
from transformations import apply_transformations

if __name__ == "__main__":
    metamodel = create_metamodel()
    model = metamodel.model_from_file("model.arch")
    apply_transformations(model)
```

### 3.5. Docker Configuration (`Dockerfile`)

The Docker configuration for the generation environment:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY . .

RUN pip install --no-cache-dir textX mysql-connector-python flask

CMD ["python", "generation.py"]
```

### 3.6. Transformations (`transformations.py`)

The transformation rules that generate the actual system components:

1. **Load Balancer Generation**:
```python
def generate_load_balancer(name, backends):
    path = f'skeleton/{name}'
    os.makedirs(path, exist_ok=True)

    with open(os.path.join(path, 'nginx.conf'), 'w') as f:
        f.write(textwrap.dedent("""
            events {
                worker_connections 1024;
            }
            
            http {
                upstream backend_servers {
                    least_conn;
        """))
        
        for backend in backends:
            f.write(f"        server {backend}:80;\n")
        
        f.write(textwrap.dedent("""
                }

                server {
                    listen 80;
                    
                    location / {
                        proxy_pass http://backend_servers;
                        proxy_set_header Host $host;
                        proxy_set_header X-Real-IP $remote_addr;
                    }
                }
            }
        """))
```

2. **Monitoring Generation**:
```python
def generate_monitoring(name, components):
    path = f'skeleton/{name}'
    os.makedirs(path, exist_ok=True)

    # Prometheus configuration
    with open(os.path.join(path, 'prometheus.yml'), 'w') as f:
        f.write(textwrap.dedent("""
            global:
              scrape_interval: 15s
              evaluation_interval: 15s

            scrape_configs:
        """))
        
        for comp_name, comp_type in components.items():
            if comp_type in ['backend', 'load_balancer']:
                f.write(textwrap.dedent(f"""
                  - job_name: '{comp_name}'
                    static_configs:
                      - targets: ['{comp_name}:80']
                        labels:
                          service: '{comp_name}'
                """))
```

## 4. Testing

To test the implemented solution, follow these steps:

1. Build and run the Docker containers:
```bash
docker-compose up --build
```

2. Access the different services:
- Frontend: `http://localhost:8001`
- Prometheus: `http://localhost:9090`
- Grafana: `http://localhost:3000` (user: admin, password: admin)

3. Verify the load balancing:
- Send multiple requests to the frontend
- Check how the load balancer distributes the requests between backends
- Monitor the metrics in Grafana

4. Check the monitoring:
- Access Grafana dashboard
- Verify that metrics are being collected from all services
- Check the request rate and response times

## 5. Results

The implementation successfully provides:

1. **Load Balancing**:
   - Even distribution of requests between backends
   - High availability
   - Automatic failover

2. **Monitoring**:
   - Real-time metrics collection
   - Visual dashboard for system health
   - Performance tracking

3. **Scalability**:
   - Easy addition of new backends
   - Horizontal scaling capability
   - Resource optimization

## 6. Conclusion

The implementation of the Load Balancer and Monitoring components significantly improves the system's:
- Reliability
- Performance
- Observability
- Maintainability

These additions make the system more robust and production-ready, providing essential features for modern web applications.